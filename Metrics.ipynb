{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Metrics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOt40kXAraO9Ajyv/3JN72u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yasntrk/metric_distances/blob/main/Metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb3yEgsNiYBQ"
      },
      "source": [
        "# <center> **Distance Metrics and Similarity** </center>\n",
        "<hr><center>\n",
        "Yasin TÜRK</center>\n",
        "<hr>\n",
        "In mathematics, a metric or distance function is a function that defines a distance between each pair of point elements of a set. A set with a metric is called a metric space. A metric induces a topology on a set, but not all topologies can be generated by a metric. A topological space whose topology can be described by a metric is called metrizable.\n",
        "<br>\n",
        "<p><center><img src=\"https://i0.wp.com/dataaspirant.com/wp-content/uploads/2015/04/cover_post_final.png\" width=800></center>\n",
        "\n",
        "Ref: <a href=\"https://bigdata-madesimple.com/implementing-the-five-most-popular-similarity-measures-in-python/\">Big Data</a><br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc8hP6DLjzvb"
      },
      "source": [
        "# <center> **Euclidean Distance** </center>\n",
        "\n",
        "<center>In mathematics, the Euclidean distance between two points in Euclidean space is the length of a line segment between the two points. It can be calculated from the Cartesian coordinates of the points using the Pythagorean theorem, therefore occasionally being called the Pythagorean distance.</center>\n",
        "\n",
        "\n",
        "<p><center><img src=\"https://bigdata-madesimple.com/wp-content/uploads/2015/06/Five-most-popular-similarity-measures-implementation-in-python-1.png\" width=600></center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjSfvyUQkc-A",
        "outputId": "1143b1a1-7a2e-4d31-eba3-332afed01f2d"
      },
      "source": [
        "from math import*\n",
        "#Euclidean Distance \n",
        "uV = [2 , 2]\n",
        "uX = [2 , 4]\n",
        "zipped = zip(uV,uX)\n",
        "Euclidean_distance = 0\n",
        "for x,y in zipped:\n",
        "  Euclidean_distance += sqrt(pow(x-y,2))\n",
        "print(Euclidean_distance)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLYBwgXAnz2O"
      },
      "source": [
        "# <center> **Manhattan Distance** </center>\n",
        "\n",
        "<center>The distance between two points measured along axes at right angles. In a plane with p1 at (x1, y1) and p2 at (x2, y2), it is |x1 - x2| + |y1 - y2|.</center>\n",
        "\n",
        "<p><center><img src=\"https://bigdata-madesimple.com/wp-content/uploads/2015/06/Five-most-popular-similarity-measures-implementation-in-python-2.png\" width=600></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUTmWcmen7-x",
        "outputId": "2a77b590-8428-4ab0-ff2b-d2942a09b6b8"
      },
      "source": [
        "from math import*\n",
        "#Manhattan Distance\n",
        "P1 = [2 , 2]\n",
        "P2 = [2 , 4]\n",
        "zipped = zip(P1,P2)\n",
        "manhattan_sum = 0\n",
        "for x,y in zipped:\n",
        "  manhattan_sum += abs(x-y)\n",
        "print(manhattan_sum)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-owB9V5rzu7"
      },
      "source": [
        "# <center> **Minkowski Distance** </center>\n",
        "\n",
        "<center>The Minkowski distance or Minkowski metric is a metric in a normed vector space which can be considered as a generalization of both the Euclidean distance and the Manhattan distance. It is named after the German mathematician Hermann Minkowski.</center>\n",
        "\n",
        "<p><center><img src=\"https://bigdata-madesimple.com/wp-content/uploads/2015/06/Five-most-popular-similarity-measures-implementation-in-python-3.png\" width=600></center>\n",
        "\n",
        "Ref: <a href=\"https://github.com/jaimezorno/Distance-Metrics/blob/main/Distance%20Metrics.ipynb\">Jaime Zornoza</a><br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkJzHCmMyDLA"
      },
      "source": [
        "# import math library \n",
        "import math\n",
        "import numpy as np\n",
        "from decimal import Decimal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIBMByxU7uPl"
      },
      "source": [
        "# Calculate the p root of a certain numeric value  \n",
        "def p_root(value, root): \n",
        "  root_value = 1 / float(root) \n",
        "  return round (Decimal(value) **\n",
        "                Decimal(root_value), 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkoIc1S371SJ",
        "outputId": "a69f9373-9bde-49db-ae9b-232ab3af1366"
      },
      "source": [
        "squared_root_3 = p_root(3,2)\n",
        "print(squared_root_3)\n",
        "squared_root_4 = p_root(4,2)\n",
        "print(squared_root_4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.732\n",
            "2.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iENXeIB774Q7"
      },
      "source": [
        "# Function implementing the Minkowski distance\n",
        "def minkowski_distance(x, y, p):    \n",
        "  # pass the p_root function to calculate \n",
        "    # all the value of vector parallely  \n",
        "  return (p_root(sum(pow(abs(a-b), p) for a, b in zip(x, y)), p))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi358Xq48BNT"
      },
      "source": [
        "# Our observations\n",
        "a = np.array((1.1, 2.2, 3.3))\n",
        "b = np.array((4.4, 5.5, 6.6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIBPhskv8GRn",
        "outputId": "df2cf05d-61ac-4ca2-ef3f-2c695d2f83bd"
      },
      "source": [
        "from scipy.spatial import distance\n",
        "# Calculate Manhattan Distance\n",
        "p = 1\n",
        "print(\"Manhattan Distance (p = 1)\")\n",
        "print(distance.minkowski(a, b, p))\n",
        "# Calculate Euclidean Distance\n",
        "p = 2\n",
        "print(\"Euclidean Distance (p = 2)\")\n",
        "print(distance.minkowski(a, b, p))\n",
        "# Calculate intermediate norm distance\n",
        "p = 1.5\n",
        "print(\"Intermidiate norm Distance (p = 1.5)\")\n",
        "print(distance.minkowski(a, b, p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Manhattan Distance (p = 1)\n",
            "9.899999999999999\n",
            "Euclidean Distance (p = 2)\n",
            "5.715767664977295\n",
            "Intermidiate norm Distance (p = 1.5)\n",
            "6.864276616071283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0ynbiKG-oqP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-hrCrzd-wcV"
      },
      "source": [
        "# <center> **Cosine Similarty** </center>\n",
        "\n",
        "<center>Cosine similarity metric finds the normalized dot product of the two attributes. By determining the cosine similarity, we will effectively try to find the cosine of the angle between the two objects. The cosine of 0° is 1, and it is less than 1 for any other angle. It is thus a judgement of orientation and not magnitude: two vectors with the same orientation have a cosine similarity of 1, two vectors at 90° have a similarity of 0, and two vectors diametrically opposed have a similarity of -1, independent of their magnitude. Cosine similarity is particularly used in positive space, where the outcome is neatly bounded in [0,1]. One of the reasons for the popularity of cosine similarity is that it is very efficient to evaluate, especially for sparse vectors.</center>\n",
        "\n",
        "<p><center><img src=\"https://bigdata-madesimple.com/wp-content/uploads/2015/06/cosine-similarity.png\" width=600></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiAkTLAiKPfR",
        "outputId": "9a920c0e-ed09-4795-dac5-9ae179327f25"
      },
      "source": [
        "from math import*\n",
        "\n",
        "def square_rooting(x):\n",
        "    return round(sqrt(sum([a*a for a in x])),3)\n",
        "\n",
        "def cosine_similarity(x,y):\n",
        "  numerator = sum(a*b for a,b in zip(x,y))\n",
        "  denominator = square_rooting(x)*square_rooting(y)\n",
        "  return round(numerator/float(denominator),3)\n",
        "\n",
        "print(cosine_similarity([3, 45, 7, 2], [2, 54, 13, 15]))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPMkigFEBFsN"
      },
      "source": [
        "# <center> **Hamming Distance** </center>\n",
        "\n",
        "<center>Hamming distance is a metric for comparing two binary data strings. While comparing two binary strings of equal length, Hamming distance is the number of bit positions in which the two bits are different. The Hamming distance between two strings, a and b is denoted as d(a,b).</center>\n",
        "\n",
        "<p><center><img src=\"https://rahimtech.com/wp-content/uploads/2021/03/Hamming-Distance.png\" width=600></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp2pocHYBzDj",
        "outputId": "15289d42-5121-40c4-b7db-c3aa05581281"
      },
      "source": [
        "a = np.array((1, 0, 1, 0, 0, 1, 0))\n",
        "b = np.array((0, 0, 1, 1,0 , 0, 1))\n",
        "hamming_distance = np.bitwise_xor(a,b)\n",
        "print(hamming_distance)\n",
        "print(hamming_distance.sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 1 0 1 1]\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}